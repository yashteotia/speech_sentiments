{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will create a speech sentiment analyser with the help of Lstms and Speech Recognizer library\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import featuretools\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer , PorterStemmer\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from keras.models import Sequential\n",
    "from string import punctuation\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2bc2702e-d6f4-df5f-b80e-50ab23a6d29e",
    "_uuid": "9b520acffb5cd85d0e1ada968ad0f12cee33a4b5"
   },
   "source": [
    "Only keeping the necessary columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_cell_guid": "89c8c923-c0bf-7b35-9ab8-e63f00b74e5a",
    "_uuid": "d2bc3bbd2ea3961c49e6673145a0a7226c160e58"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('Sentiment.csv')\n",
    "data = data[['text','sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @NancyLeeGrahn: How did everyone feel about...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @ScottWalker: Didn't catch the full #GOPdeb...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @TJMShow: No mention of Tamir Rice and the ...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @RobGeorge: That Carly Fiorina is trending ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @DanScavino: #GOPDebate w/ @realDonaldTrump...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "0  RT @NancyLeeGrahn: How did everyone feel about...   Neutral\n",
       "1  RT @ScottWalker: Didn't catch the full #GOPdeb...  Positive\n",
       "2  RT @TJMShow: No mention of Tamir Rice and the ...   Neutral\n",
       "3  RT @RobGeorge: That Carly Fiorina is trending ...  Positive\n",
       "4  RT @DanScavino: #GOPDebate w/ @realDonaldTrump...  Positive"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text, stem_words=True):\n",
    "    import re\n",
    "    from string import punctuation\n",
    "    from nltk.stem import SnowballStemmer\n",
    "    from nltk.corpus import stopwords\n",
    "    \n",
    "    def pad_str(s):\n",
    "        return ' '+s+' '\n",
    "    \n",
    "    if pd.isnull(text):\n",
    "        return ''\n",
    "\n",
    "    \n",
    "    if type(text) != str or text=='':\n",
    "        return ''\n",
    "\n",
    "    # Clean the text\n",
    "    text = re.sub(\"\\'s\", \" \", text) # we have cases like \"Sam is\" or \"Sam's\" (i.e. his) these two cases aren't separable, I choose to compromise are kill \"'s\" directly\n",
    "    text = re.sub(\" whats \", \" what is \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(\"can't\", \"can not\", text)\n",
    "    text = re.sub(\"n't\", \" not \", text)\n",
    "    text = re.sub(\"i'm\", \"i am\", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(\"\\'re\", \" are \", text)\n",
    "    text = re.sub(\"\\'d\", \" would \", text)\n",
    "    text = re.sub(\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(\"e\\.g\\.\", \" eg \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(\"b\\.g\\.\", \" bg \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(\"(\\d+)(kK)\", \" \\g<1>000 \", text)\n",
    "    text = re.sub(\"e-mail\", \" email \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(\"(the[\\s]+|The[\\s]+)?U\\.S\\.A\\.\", \" America \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(\"(the[\\s]+|The[\\s]+)?United State(s)?\", \" America \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(\"\\(s\\)\", \" \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(\"[c-fC-F]\\:\\/\", \" disk \", text)    \n",
    "    text = re.sub('(?<=[0-9])\\,(?=[0-9])', \"\", text)   \n",
    "    text = re.sub('\\$', \" dollar \", text)\n",
    "    text = re.sub('\\%', \" percent \", text)\n",
    "    text = re.sub('\\&', \" and \", text)\n",
    "    text = re.sub('[^\\x00-\\x7F]+', pad_str(SPECIAL_TOKENS['non-ascii']), text) \n",
    "    text = re.sub(\"(?<=[0-9])rs \", \" rs \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(\" rs(?=[0-9])\", \" rs \", text, flags=re.IGNORECASE)\n",
    "   # clean text rules get from : https://www.kaggle.com/currie32/the-importance-of-cleaning-text\n",
    "    text = re.sub(r\" (the[\\s]+|The[\\s]+)?US(A)? \", \" America \", text)\n",
    "    text = re.sub(r\" UK \", \" England \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" india \", \" India \", text)\n",
    "    text = re.sub(r\" switzerland \", \" Switzerland \", text)\n",
    "    text = re.sub(r\" china \", \" China \", text)\n",
    "    text = re.sub(r\" chinese \", \" Chinese \", text) \n",
    "    text = re.sub(r\" imrovement \", \" improvement \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" intially \", \" initially \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" quora \", \" Quora \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" dms \", \" direct messages \", text, flags=re.IGNORECASE)  \n",
    "    text = re.sub(r\" demonitization \", \" demonetization \", text, flags=re.IGNORECASE) \n",
    "    text = re.sub(r\" actived \", \" active \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" kms \", \" kilometers \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" cs \", \" computer science \", text, flags=re.IGNORECASE) \n",
    "    text = re.sub(r\" upvote\", \" up vote\", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" iPhone \", \" phone \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" \\0rs \", \" rs \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" calender \", \" calendar \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" ios \", \" operating system \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" gps \", \" GPS \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" gst \", \" GST \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" programing \", \" programming \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" bestfriend \", \" best friend \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" dna \", \" DNA \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" III \", \" 3 \", text)\n",
    "    text = re.sub(r\" banglore \", \" Banglore \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" J K \", \" JK \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" J\\.K\\. \", \" JK \", text, flags=re.IGNORECASE)\n",
    "    \n",
    "    # replace the float numbers with a random number, it will be parsed as number afterward, and also been replaced with word \"number\"\n",
    "    \n",
    "    text = re.sub('[0-9]+\\.[0-9]+', \" 87 \", text)\n",
    "  \n",
    "    \n",
    "    # Remove punctuation from text\n",
    "    text = ''.join([c for c in text if c not in punctuation]).lower()\n",
    "       # Return a list of words\n",
    "    return text\n",
    "SPECIAL_TOKENS = {\n",
    "    'quoted': 'quoted_item',\n",
    "    'non-ascii': 'non_ascii_word',\n",
    "    'undefined': 'something'\n",
    "}\n",
    "data[\"text\"] = data[\"text\"].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_cell_guid": "43632d2d-6160-12ce-48b0-e5eb1c207076",
    "_uuid": "d0f8b4542106a279f7398db7285ae5e370b2e813"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4472\n",
      "16986\n"
     ]
    }
   ],
   "source": [
    "data = data[data.sentiment != \"Neutral\"]\n",
    "print(data[ data['sentiment'] == 'Positive'].size)\n",
    "print(data[ data['sentiment'] == 'Negative'].size)\n",
    "for idx,row in data.iterrows():\n",
    "    row[0] = row[0].replace('rt',' ')    \n",
    "max_fatures = 2000\n",
    "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
    "tokenizer.fit_on_texts(data['text'].values)\n",
    "X = tokenizer.texts_to_sequences(data['text'].values)\n",
    "X = pad_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_cell_guid": "1ba3cf60-a83c-9c21-05e0-b14303027e93",
    "_uuid": "05cb9ef0ec9e0a4067e3ab7c1bda7b2c1211feda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 29, 128)           256000    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_2 (Spatial (None, 29, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 196)               254800    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 394       \n",
      "=================================================================\n",
      "Total params: 511,194\n",
      "Trainable params: 511,194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 128\n",
    "lstm_out = 196\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_fatures, embed_dim,input_length = X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "15f4ee61-47e4-88c4-4b81-98a85237333f",
    "_uuid": "2dae0f3b95a4ba533453c512e573560a8358e162"
   },
   "source": [
    "Hereby I declare the train and test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_cell_guid": "b35748b8-2353-3db2-e571-5fd22bb93eb0",
    "_uuid": "a380bbfae2d098d407b138fc44622c9913a31c07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8583, 29) (8583, 2)\n",
      "(2146, 29) (2146, 2)\n"
     ]
    }
   ],
   "source": [
    "Y = pd.get_dummies(data['sentiment']).values\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.20, random_state = 42)\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_cell_guid": "d5e499ac-2eba-6ff7-8d9a-ff65eb04099b",
    "_uuid": "d0b239912cf67294a9f5af6883bb159c44318fc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " - 9s - loss: 0.4269 - acc: 0.8198\n",
      "Epoch 2/20\n",
      " - 8s - loss: 0.3188 - acc: 0.8648\n",
      "Epoch 3/20\n",
      " - 8s - loss: 0.2789 - acc: 0.8876\n",
      "Epoch 4/20\n",
      " - 7s - loss: 0.2621 - acc: 0.8929\n",
      "Epoch 5/20\n",
      " - 8s - loss: 0.2326 - acc: 0.9057\n",
      "Epoch 6/20\n",
      " - 8s - loss: 0.2117 - acc: 0.9115\n",
      "Epoch 7/20\n",
      " - 7s - loss: 0.1944 - acc: 0.9215\n",
      "Epoch 8/20\n",
      " - 8s - loss: 0.1798 - acc: 0.9286\n",
      "Epoch 9/20\n",
      " - 8s - loss: 0.1718 - acc: 0.9286\n",
      "Epoch 10/20\n",
      " - 8s - loss: 0.1600 - acc: 0.9352\n",
      "Epoch 11/20\n",
      " - 8s - loss: 0.1479 - acc: 0.9398\n",
      "Epoch 12/20\n",
      " - 8s - loss: 0.1415 - acc: 0.9414\n",
      "Epoch 13/20\n",
      " - 8s - loss: 0.1318 - acc: 0.9452\n",
      "Epoch 14/20\n",
      " - 8s - loss: 0.1249 - acc: 0.9487\n",
      "Epoch 15/20\n",
      " - 8s - loss: 0.1239 - acc: 0.9515\n",
      "Epoch 16/20\n",
      " - 8s - loss: 0.1143 - acc: 0.9536\n",
      "Epoch 17/20\n",
      " - 8s - loss: 0.1095 - acc: 0.9542\n",
      "Epoch 18/20\n",
      " - 8s - loss: 0.1110 - acc: 0.9565\n",
      "Epoch 19/20\n",
      " - 8s - loss: 0.1061 - acc: 0.9576\n",
      "Epoch 20/20\n",
      " - 8s - loss: 0.0968 - acc: 0.9605\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x27578d07198>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "model.fit(X_train, Y_train, epochs = 20, batch_size=batch_size, verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4ebd7bc1-53c0-0e31-a0b0-b6d0a3017434",
    "_uuid": "47e99d7ed1f27a85eb01dbafc71b66b329fb1d12"
   },
   "source": [
    "Extracting a validation set, and measuring score and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "_cell_guid": "a970f412-722f-6d6d-72c8-325d0901ccef",
    "_uuid": "7872f6ea819a5d4d08394ba6db8436f9cb2cfe1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.82\n",
      "acc: 0.83\n"
     ]
    }
   ],
   "source": [
    "# Here we are creating a validation set to test how good our model is\n",
    "validation_size = 1500\n",
    "X_validate = X_test[-validation_size:]\n",
    "Y_validate = Y_test[-validation_size:]\n",
    "X_test = X_test[:-validation_size]\n",
    "Y_test = Y_test[:-validation_size]\n",
    "score,acc = model.evaluate(X_test, Y_test, verbose = 2, batch_size = batch_size)\n",
    "print(\"score: %.2f\" % (score))\n",
    "print(\"acc: %.2f\" % (acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "018ebf39-9414-27d0-232c-a34de051feaf",
    "_uuid": "4b54f18bbf22a953c60f271c318cb076e684df9c"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "_cell_guid": "1add73e9-c6fb-7e4c-8715-ea92f519d2a6",
    "_uuid": "f80e9f3cf281adb3ab0357cbf6f886eb1dce3005"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive accuracy of the model 50.33557046979866 %\n",
      "negative accuracy of the model 92.09650582362728 %\n",
      "Total_accuracy is 83.8 \n"
     ]
    }
   ],
   "source": [
    "pos_tot, neg_tot , pos_correct, neg_correct = 0, 0, 0, 0\n",
    "\n",
    "\n",
    "for x in range(len(X_validate)):\n",
    "    result = model.predict(X_validate[x].reshape(1,X_test.shape[1]),batch_size=1,verbose = 2)[0]\n",
    "    if np.argmax(result) == np.argmax(Y_validate[x]):\n",
    "        if np.argmax(Y_validate[x]) == 0:\n",
    "            neg_correct += 1\n",
    "        else:\n",
    "            pos_correct += 1  \n",
    "    if np.argmax(Y_validate[x]) == 0:\n",
    "        neg_tot += 1\n",
    "    else:\n",
    "        pos_tot += 1\n",
    "\n",
    "print(\"positive accuracy of the model\", pos_correct/pos_cnt*100, \"%\")\n",
    "print(\"negative accuracy of the model\", neg_correct/neg_cnt*100, \"%\")\n",
    "print(\"Total_accuracy is\", (pos_correct + neg_correct)/(pos_cnt + neg_cnt)*100,\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above predictions are more accurate for negative results because there is more training data for negative tweets but there is not much data for positive tweets to be trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x27578d7e240>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x=data.sentiment.value_counts().index, y=data.sentiment.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speak  :\n",
      "I said- I hate the way you are angry all the time\n",
      "<class 'str'>\n",
      "['I hate the way you are angry all the time']\n",
      "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0   10  366    1  267   14   23 1190   51    1\n",
      "   110]]\n",
      "negative\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "r = sr.Recognizer()\n",
    "with sr.Microphone() as source:\n",
    "    print(\"Speak  :\")\n",
    "    audio = r.listen(source)\n",
    "    text = r.recognize_google(audio)\n",
    "    print(\"I said- \" +text)\n",
    "    text2=list(text)\n",
    "    print(type(text))\n",
    "    text2[0 : len(text)+1] = [''.join(text2[0 : len(text)+1])]\n",
    "    print(text2)\n",
    "    twt = tokenizer.texts_to_sequences(text2)\n",
    "    twt = pad_sequences(twt, maxlen=29, dtype='int32', value=0)\n",
    "    print(twt)\n",
    "    sentiment = model.predict(twt,batch_size=1,verbose = 2)[0]\n",
    "    if(np.argmax(sentiment) == 0):\n",
    "        print(\"negative\")\n",
    "    elif (np.argmax(sentiment) == 1):\n",
    "        print(\"positive\")     \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "24c64f46-edd1-8d0b-7c7c-ef50fd26b2fd",
    "_uuid": "d9aac68e2013b3beffb6a764cc5b85be83073e66"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c611b55c-92e4-4a33-8e82-1812bef6193d",
    "_uuid": "8b10995b0832ec98ba0c75832186fcb09b1a2d5f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_change_revision": 0,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
